import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, random_split

def get_cifar100_custom_split(batch_size=128, train_ratio=0.8):
    """CIFAR-100ì„ ì§ì ‘ 80:20ìœ¼ë¡œ ë¶„í• í•˜ëŠ” í•¨ìˆ˜"""
    mean = (0.5071, 0.4865, 0.4409)
    std = (0.2673, 0.2564, 0.2762)
    
    # Training augmentations
    train_transforms = transforms.Compose([
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.ToTensor(),
        transforms.Normalize(mean, std),
    ])
    
    # Validation transforms (no augmentation)
    val_transforms = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ])
    
    # ë°©ë²• 1: ì›ë³¸ train set(50,000)ì„ 80:20ìœ¼ë¡œ ë¶„í• 
    full_train_dataset = torchvision.datasets.CIFAR100(
        root='./data', train=True, download=True, transform=None  # transformëŠ” ë‚˜ì¤‘ì—
    )
    
    # 80:20 ë¶„í•  ê³„ì‚°
    total_size = len(full_train_dataset)  # 50,000
    train_size = int(train_ratio * total_size)  # 40,000
    val_size = total_size - train_size  # 10,000
    
    print(f"ğŸ“Š Custom split:")
    print(f"   Total: {total_size:,}")
    print(f"   Train: {train_size:,} ({train_size/total_size*100:.1f}%)")
    print(f"   Val: {val_size:,} ({val_size/total_size*100:.1f}%)")
    
    # ëœë¤ ë¶„í•  (ì¬í˜„ ê°€ëŠ¥í•˜ê²Œ seed ê³ ì •)
    generator = torch.Generator().manual_seed(42)
    train_indices, val_indices = random_split(
        range(total_size), [train_size, val_size], generator=generator
    )
    
    # ì¸ë±ìŠ¤ë¥¼ ì‹¤ì œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    train_idx = train_indices.indices
    val_idx = val_indices.indices
    
    # Subset ìƒì„± (transform ì ìš©)
    train_dataset = torch.utils.data.Subset(full_train_dataset, train_idx)
    val_dataset = torch.utils.data.Subset(full_train_dataset, val_idx)
    
    # Transform ì ìš©ì„ ìœ„í•œ ì»¤ìŠ¤í…€ Dataset í´ë˜ìŠ¤
    class TransformedDataset(torch.utils.data.Dataset):
        def __init__(self, subset, transform):
            self.subset = subset
            self.transform = transform
            
        def __len__(self):
            return len(self.subset)
            
        def __getitem__(self, idx):
            image, label = self.subset[idx]
            if self.transform:
                image = self.transform(image)
            return image, label
    
    # Transform ì ìš©
    train_dataset_transformed = TransformedDataset(train_dataset, train_transforms)
    val_dataset_transformed = TransformedDataset(val_dataset, val_transforms)
    
    # DataLoader ìƒì„±
    train_loader = DataLoader(
        train_dataset_transformed, batch_size=batch_size, shuffle=True,
        num_workers=4, pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset_transformed, batch_size=batch_size, shuffle=False,
        num_workers=4, pin_memory=True
    )
    
    return train_loader, val_loader

def get_cifar100_standard_split(batch_size=128):
    """í‘œì¤€ CIFAR-100 ë¶„í•  (í˜„ì¬ ë°©ì‹)"""
    mean = (0.5071, 0.4865, 0.4409)
    std = (0.2673, 0.2564, 0.2762)
    
    train_transforms = transforms.Compose([
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.ToTensor(),
        transforms.Normalize(mean, std),
    ])
    
    val_transforms = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ])
    
    # í‘œì¤€ ë¶„í• : train=True (50k), train=False (10k)
    train_dataset = torchvision.datasets.CIFAR100(
        root='./data', train=True, download=True, transform=train_transforms
    )
    
    val_dataset = torchvision.datasets.CIFAR100(
        root='./data', train=False, download=True, transform=val_transforms
    )
    
    print(f"ğŸ“Š Standard split:")
    print(f"   Train: {len(train_dataset):,} (83.3%)")
    print(f"   Val: {len(val_dataset):,} (16.7%)")
    
    train_loader = DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True,
        num_workers=4, pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset, batch_size=batch_size, shuffle=False,
        num_workers=4, pin_memory=True
    )
    
    return train_loader, val_loader

def compare_splits():
    """ë‘ ë¶„í•  ë°©ì‹ ë¹„êµ"""
    print("ğŸ” CIFAR-100 ë¶„í•  ë°©ì‹ ë¹„êµ\n")
    
    # ë°©ë²• 1: í‘œì¤€ ë¶„í• 
    print("1ï¸âƒ£ í‘œì¤€ ë¶„í•  (í˜„ì¬ ë°©ì‹)")
    train_loader1, val_loader1 = get_cifar100_standard_split(batch_size=64)
    
    print()
    
    # ë°©ë²• 2: ì»¤ìŠ¤í…€ ë¶„í• 
    print("2ï¸âƒ£ ì»¤ìŠ¤í…€ 80:20 ë¶„í• ")
    train_loader2, val_loader2 = get_cifar100_custom_split(batch_size=64, train_ratio=0.8)
    
    print("\n" + "="*50)
    print("ğŸ’¡ ì–´ë–¤ ë°©ì‹ì„ ì„ íƒí• ê¹Œ?")
    print("   - í‘œì¤€ ë¶„í• : ë…¼ë¬¸ ë¹„êµìš©, ë” ë§ì€ í•™ìŠµ ë°ì´í„°")
    print("   - ì»¤ìŠ¤í…€ ë¶„í• : ì •í™•íˆ 80:20, ë™ì¼í•œ ë°ì´í„° ì†ŒìŠ¤")

if __name__ == "__main__":
    compare_splits() 